{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imorting necisary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import unirep\n",
    "from data_utils import aa_seq_to_int\n",
    "import csv\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Bio import SeqIO\n",
    "from Preprocessing import to_binary\n",
    "\n",
    "#Define\n",
    "RANDOM_SEED = 42\n",
    "USE_FULL_1900_DIM_MODEL = True # if True use 1900 dimensional model, else use 64 dimensional one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring and initiates Unitep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: aws: not found\n",
      "WARNING:tensorflow:From /home/sandra/Documents/PHD_projects/Embedding/Unirep/UniRep/unirep.py:114: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "(?, 1900)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set seeds\n",
    "tf.set_random_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "if USE_FULL_1900_DIM_MODEL:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/1900_weights/ 1900_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler1900 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./1900_weights\"\n",
    "    \n",
    "else:\n",
    "    # Sync relevant weight files\n",
    "    !aws s3 sync --no-sign-request --quiet s3://unirep-public/64_weights/ 64_weights/\n",
    "    \n",
    "    # Import the mLSTM babbler model\n",
    "    from unirep import babbler64 as babbler\n",
    "    \n",
    "    # Where model weights are stored.\n",
    "    MODEL_WEIGHT_PATH = \"./64_weights\"\n",
    "\n",
    "batch_size = 32\n",
    "b = babbler(batch_size=batch_size, model_path=MODEL_WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'test.csv'\n",
    "unirep_dict = {'id': [], 'property_ogt': [], 'seq':[], 'rep':[]}\n",
    "\n",
    "if(file_name[-3:]=='csv'):\n",
    "    with open(file_name, newline='') as csvfile:   \n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for i, row in enumerate(reader):\n",
    "            unirep_dict['id'].append(row['id'])\n",
    "            unirep_dict['property_ogt'].append(float(row['property_ogt']))\n",
    "            unirep_dict['seq'].append(row['seq'])\n",
    "elif file_name[-5:]=='fasta':\n",
    "    for rec in SeqIO.parse(file_name,'fasta'):\n",
    "        topt_dict['id'].append(rec.id)\n",
    "        topt_dict['ogt'].append(float(rec.description.split()[-1]))\n",
    "        topt_dict['seq'].append(rec.seq)\n",
    "        topt_dict['seq_bin'].append(to_binary(rec.seq))\n",
    "    \n",
    "else:\n",
    "    print('Data format {} is not suported'.format(file_name.split('.')[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train, val and test set and Sort data set by sequense length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "\n",
    "X_train, X_Test_Val, y_train, y_Test_Val = train_test_split( unirep_dict['seq'], unirep_dict['property_ogt'], test_size=0.3, random_state=RANDOM_SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_Test_Val , y_Test_Val, test_size=0.5, random_state=RANDOM_SEED)\n",
    "\n",
    "# Sort Training set\n",
    "sorted_zip_train = sorted(zip(X_train, y_train), key=lambda pair: len(pair[0]))\n",
    "X_train = [X for X, _ in sorted_zip_train]\n",
    "y_train = [y for _,y in sorted_zip_train]\n",
    "\n",
    "# Sort Validation set\n",
    "sorted_zip_val = sorted(zip(X_val, y_val), key=lambda pair: len(pair[0]))\n",
    "X_val = [X for X, _ in sorted_zip_val]\n",
    "y_val = [y for _, y in sorted_zip_val]\n",
    "\n",
    "# Sort Test set\n",
    "sorted_zip_test = sorted(zip(X_test, y_test), key=lambda pair: len(pair[0]))\n",
    "X_test = [X for X, _ in sorted_zip_test]\n",
    "y_test = [y for _, y in sorted_zip_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Creating top model #######################################\n",
    "\n",
    "hid=b._rnn_size     # Not correct way to get hidden variable\n",
    "dense_nodes_1 = 128 \n",
    "dense_nodes_2 = 128\n",
    "prop_size = 20 # should be set to 20 if Evo tuning \n",
    "\n",
    "# Variable declaration UniRep mLSTM\n",
    "labels_prop = tf.placeholder(tf.float32,(None,prop_size), name='Target_prop')\n",
    "labels_evo = tf.placeholder(tf.float32,(None,prop_size), name='Target_evo')\n",
    "hidden_states_p = tf.placeholder(tf.float32, (None,None,hid), name='hs')\n",
    "non_pad_len_p = tf.placeholder(tf.int32, (None,), name='batch_size_hs')\n",
    "lr = tf.placeholder(tf.float32, shape=[], name='learningrate')\n",
    "size = tf.placeholder(tf.int32, shape=[], name='Size_of_batch')\n",
    "\n",
    "# Variable declarations top model\n",
    "with tf.variable_scope('top_model'):\n",
    "\n",
    "    beta1= tf.get_variable(shape =[hid],  initializer=tf.initializers.constant(1,dtype=tf.float32), name='Beta_1')\n",
    "    gamma1= tf.get_variable(shape =[hid],  initializer=tf.initializers.constant(0,dtype=tf.float32), name='gamma_1')\n",
    "\n",
    "    w1 = tf.get_variable(name='Weights_top1', shape=[hid,dense_nodes_1] )\n",
    "    b1 = tf.get_variable(shape=[dense_nodes_1], name='Bias_top1')\n",
    "    \n",
    "    beta2= tf.get_variable(shape =[dense_nodes_1],  initializer=tf.initializers.constant(1,dtype=tf.float32), name='Beta_2')\n",
    "    gamma2= tf.get_variable(shape =[dense_nodes_1],  initializer=tf.initializers.constant(0,dtype=tf.float32), name='gamma_2')\n",
    "    \n",
    "    w2 = tf.get_variable(shape=[dense_nodes_1,dense_nodes_2], name='Wights_top2')\n",
    "    b2 = tf.get_variable(shape=[dense_nodes_2], name='Bias_top2')\n",
    "    \n",
    "    beta3= tf.get_variable(shape =[dense_nodes_2],  initializer=tf.initializers.constant(1,dtype=tf.float32), name='Beta_3')\n",
    "    gamma3= tf.get_variable(shape =[dense_nodes_2],  initializer=tf.initializers.constant(0,dtype=tf.float32), name='gamma_3')\n",
    "\n",
    "    w3 = tf.get_variable(shape=[dense_nodes_2,prop_size], name='Weights_top3')\n",
    "    b3 = tf.get_variable(shape=[1], name='Bias_top3')\n",
    "\n",
    "# Get build parameters from UniRep model    \n",
    "final_hidden, x_placeholder, batch_size_placeholder, seq_length_placeholder, initial_state_placeholder = (\n",
    "    b.get_rep_ops())\n",
    "\n",
    "# Generate features as in article\n",
    "e = lambda j: tf.reduce_mean(tf.gather_nd(hidden_states_p,\n",
    "                                               tf.stack([tf.ones(non_pad_len_p[j],dtype=tf.int32)*j,\n",
    "                                                tf.range(non_pad_len_p[j],dtype=tf.int32)], axis=1)), axis=0) #for j in tf.range(size)]\n",
    "features = tf.map_fn(e,tf.range(size, dtype=tf.int32), dtype=tf.float32)\n",
    "\n",
    "# Top Model build\n",
    "mean, variance = tf.nn.moments(final_hidden, axes = [0])\n",
    "lstm_out = tf.nn.batch_normalization( final_hidden, mean, variance, beta1, gamma1,variance_epsilon = 1e-6,name=None)\n",
    "\n",
    "dens1 = tf.add(tf.matmul(lstm_out,w1),b1)\n",
    "mean1, variance1 = tf.nn.moments(dens1, axes = [0])\n",
    "bn1 = tf.nn.batch_normalization( dens1, mean1, variance1, beta2, gamma2,variance_epsilon = 1e-6,name=None)\n",
    "akt1 = tf.nn.relu(bn1)\n",
    "do1 = tf.nn.dropout(akt1, 0.2)\n",
    "\n",
    "dens2 = tf.add(tf.matmul(do1,w2),b2)\n",
    "mean2, variance2 = tf.nn.moments(dens2, axes = [0])\n",
    "bn2 = tf.nn.batch_normalization( dens2, mean2, variance2, beta3, gamma3,variance_epsilon = 1e-6,name=None)\n",
    "akt2 = tf.nn.relu(bn2)\n",
    "do2 = tf.nn.dropout(akt2, 0.05)\n",
    "\n",
    "predictions_prop = tf.add(tf.matmul(do2,w3),b3)\n",
    "predictions_evo = tf.nn.softmax(tf.add(tf.matmul(do2,w3),b3))\n",
    "\n",
    "# Loss functions\n",
    "loss_prop = tf.losses.mean_squared_error(\n",
    "        labels_prop,\n",
    "        predictions_prop\n",
    "        )\n",
    "loss_evo = tf.losses.mean_squared_error(\n",
    "        labels_evo,\n",
    "        predictions_evo\n",
    "        )\n",
    "\n",
    "# optimizers and backprop\n",
    "opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "minimize_prop = opt.minimize(loss=loss_prop)\n",
    "minimize_evo = opt.minimize(loss=loss_evo)\n",
    "\n",
    "#Callbacks\n",
    "\n",
    "SS_res = tf.reduce_sum(tf.square(labels_prop - predictions_prop))\n",
    "SS_tot = tf.reduce_sum(tf.square(labels_prop - tf.reduce_mean(labels_prop)))\n",
    "k_coff = 1 - SS_res / (SS_tot + 1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prop tune mLSTM layer (with proper truncated backpropagation through time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Loss:  1685.2069270436357 Coeff_k:  -3.1540443839096444 val_Loss:  1141.9253005981445 val_Coeff_k:  -2.5947561264038086\n",
      "epoch:  1\n",
      "Loss:  869.4872778915776 Coeff_k:  -1.1396325739418587 val_Loss:  827.1458206176758 val_Coeff_k:  -1.505938544869423\n",
      "epoch:  2\n",
      "Loss:  747.2097435927975 Coeff_k:  -0.8509958488185231 val_Loss:  748.604850769043 val_Coeff_k:  -1.3671105355024338\n",
      "epoch:  3\n",
      "Loss:  708.1513500678831 Coeff_k:  -0.7420313242005139 val_Loss:  680.166618347168 val_Coeff_k:  -1.1381970345973969\n",
      "epoch:  4\n",
      "Loss:  670.3283795612616 Coeff_k:  -0.6683197632068542 val_Loss:  654.0018463134766 val_Coeff_k:  -1.0941781848669052\n",
      "epoch:  5\n",
      "Loss:  713.2685130049542 Coeff_k:  -0.770207844129423 val_Loss:  725.6993026733398 val_Coeff_k:  -1.2858849614858627\n",
      "epoch:  6\n",
      "Loss:  678.9382577291349 Coeff_k:  -0.7105784532500478 val_Loss:  706.0018653869629 val_Coeff_k:  -1.2140212655067444\n",
      "epoch:  7\n",
      "Loss:  682.863632574314 Coeff_k:  -0.6632370570810828 val_Loss:  642.0657196044922 val_Coeff_k:  -0.9404079765081406\n",
      "epoch:  8\n",
      "Loss:  675.2134533393671 Coeff_k:  -0.6688696814746393 val_Loss:  680.5090866088867 val_Coeff_k:  -1.115397498011589\n",
      "epoch:  9\n",
      "Loss:  668.6266591141864 Coeff_k:  -0.6578618171738414 val_Loss:  637.3200988769531 val_Coeff_k:  -0.996311753988266\n"
     ]
    }
   ],
   "source": [
    "############################## Training regeme TBT ###################################\n",
    "\n",
    "# Trunkated backprop parameters\n",
    "grad_stop = 40 # parameter needs to be larger then the difference within a mini-batch\n",
    "size_train = (len(X_train))//batch_size # number of minibatches per training epoch\n",
    "size_val = len(X_val)//batch_size  # number of minibatches per validation epoch\n",
    "epoch = 10\n",
    "learningrate = 0.005\n",
    "\n",
    "# Initiate callback logg arrays\n",
    "loss_acc = np.zeros(epoch)\n",
    "loss_acc_val = np.zeros(epoch)\n",
    "k_coff_acc = np.zeros(epoch)\n",
    "k_coff_acc_val = np.zeros(epoch)\n",
    "\n",
    "#Initiate session for Prop tuning\n",
    "sess = tf.Session()\n",
    "unirep.initialize_uninitialized(sess)\n",
    "\n",
    "for k in range(epoch):\n",
    "    # Training loop\n",
    "    for i in range(size_train):\n",
    "        index = np.random.randint(0,size_train-batch_size) # creating random variable for batch creation\n",
    "        batch = X_train[index:batch_size+index]\n",
    "        labels = np.array(y_train[index:batch_size+index], dtype=np.float32)\n",
    "        labels = labels.reshape([labels.shape[0],1])\n",
    "        int_seq = list(map(aa_seq_to_int, batch))\n",
    "        \n",
    "        non_pad_len_whole = np.array([len(int_seq[i]) for i in range(len(int_seq))], dtype=np.int32)\n",
    "        max_len_batch = np.max(non_pad_len_whole)\n",
    "        min_len_batch = np.min(non_pad_len_whole)\n",
    "        non_pad_len_part = np.array([max_len_batch-grad_stop for i in range(len(int_seq))], dtype=np.int32)\n",
    "        tmp = np.zeros([batch_size, max_len_batch], dtype=np.float32)\n",
    "        for j, seq in enumerate(int_seq):\n",
    "            tmp[j,:len(seq)] = seq\n",
    "        int_seq = tmp\n",
    "\n",
    "        # Truncated gradient decent through time\n",
    "        if max_len_batch > grad_stop+1:\n",
    "            final_state_, fh_ = sess.run([b._final_state, final_hidden], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                                b._minibatch_x_placeholder: int_seq[:,:-grad_stop],\n",
    "                                                                                seq_length_placeholder: non_pad_len_part,\n",
    "                                                                                b._initial_state_placeholder: b._zero_state})\n",
    "\n",
    "            \n",
    "            [_, l,m] = sess.run([minimize_prop, loss_prop, k_coff], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                                b._minibatch_x_placeholder: int_seq[:,-grad_stop:],\n",
    "                                                                                labels_prop: labels,\n",
    "                                                                                seq_length_placeholder: non_pad_len_whole,\n",
    "                                                                                b._initial_state_placeholder: (final_state_[0], fh_),\n",
    "                                                                                lr: learningrate})\n",
    "        else:\n",
    "            [_, l,m] = sess.run([minimize_prop, loss, k_coff], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                                b._minibatch_x_placeholder: int_seq,\n",
    "                                                                                labels_prop: labels,\n",
    "                                                                                seq_length_placeholder: non_pad_len_whole,\n",
    "                                                                                b._initial_state_placeholder: b._zero_state,\n",
    "                                                                                lr: learningrate})\n",
    "        loss_acc[k] += l/size_train\n",
    "        k_coff_acc[k] += m/size_train\n",
    "    # Validation loop\n",
    "    for i in range(size_val):\n",
    "        \n",
    "        batch = X_test[i*batch_size:batch_size*i+batch_size]\n",
    "        labels = np.array(y_test[i*batch_size:batch_size*i+batch_size], dtype=np.float32)\n",
    "        labels = labels.reshape([labels.shape[0],1])\n",
    "\n",
    "        int_seq = list(map(aa_seq_to_int, batch))\n",
    "        non_pad_len_ = np.array([len(int_seq[i]) for i in range(len(int_seq))])\n",
    "        max_len_batch = np.max(non_pad_len_)\n",
    "        min_len_batch = np.min(non_pad_len_)\n",
    "        tmp = np.zeros([batch_size, max_len_batch], dtype=np.float32)\n",
    "        for j, seq in enumerate(int_seq):\n",
    "            tmp[j,:len(seq)] = seq\n",
    "        int_seq = tmp\n",
    "        \n",
    "        \n",
    "        # Validation does not need to be split in two operations \n",
    "        [l_val,m_val] = sess.run([loss_prop, k_coff], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                            b._minibatch_x_placeholder: int_seq,\n",
    "                                                                            labels_prop: labels,\n",
    "                                                                            seq_length_placeholder: non_pad_len_whole,\n",
    "                                                                            b._initial_state_placeholder: b._zero_state})\n",
    "\n",
    "        \n",
    "         \n",
    "        loss_acc_val[k] += l_val/size_val\n",
    "        k_coff_acc_val[k] += m_val/size_val\n",
    "    print('epoch: ', k)\n",
    "    print('Loss: ', loss_acc[k], 'Coeff_k: ', k_coff_acc[k], 'val_Loss: ', loss_acc_val[k], 'val_Coeff_k: ', k_coff_acc_val[k])\n",
    "    \n",
    "    #  Simple learning rate decrease algorithm (Should be upgraded to uppdate on plateau) \n",
    "    if k%10 == 0 and k>0:\n",
    "        learningrate *= 0.8\n",
    "        print('learning rate: ', learningrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evo tune mLSTM layer (with proper truncated backpropagation through time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 85)\n",
      "(32, 75)\n",
      "(32, 65)\n",
      "(32, 87)\n",
      "(32, 57)\n",
      "(32, 51)\n",
      "(32, 41)\n",
      "(32, 87)\n",
      "(32, 52)\n",
      "(32, 113)\n",
      "(32, 76)\n",
      "(32, 98)\n",
      "(32, 61)\n",
      "(32, 83)\n",
      "(32, 47)\n",
      "(32, 53)\n",
      "(32, 99)\n",
      "(32, 111)\n",
      "(32, 76)\n",
      "(32, 93)\n",
      "(32, 54)\n",
      "(32, 54)\n",
      "(32, 91)\n",
      "(32, 82)\n",
      "(32, 67)\n",
      "(32, 54)\n",
      "(32, 114)\n",
      "(32, 41)\n",
      "epoch:  0\n",
      "Loss:  0.07312739640474318\n",
      "(32, 107)\n",
      "(32, 48)\n",
      "(32, 107)\n",
      "(32, 67)\n",
      "(32, 89)\n",
      "(32, 101)\n",
      "(32, 87)\n",
      "(32, 70)\n",
      "(32, 118)\n",
      "(32, 41)\n",
      "(32, 57)\n",
      "(32, 60)\n",
      "(32, 53)\n",
      "(32, 111)\n",
      "(32, 92)\n",
      "(32, 64)\n",
      "(32, 60)\n",
      "(32, 68)\n",
      "(32, 56)\n",
      "(32, 107)\n",
      "(32, 54)\n",
      "(32, 49)\n",
      "(32, 79)\n",
      "(32, 57)\n",
      "(32, 57)\n",
      "(32, 63)\n",
      "(32, 46)\n",
      "(32, 110)\n",
      "epoch:  1\n",
      "Loss:  0.07155401904771969\n",
      "(32, 79)\n",
      "(32, 57)\n",
      "(32, 81)\n",
      "(32, 98)\n",
      "(32, 103)\n",
      "(32, 54)\n",
      "(32, 75)\n",
      "(32, 67)\n",
      "(32, 75)\n",
      "(32, 120)\n",
      "(32, 46)\n",
      "(32, 108)\n",
      "(32, 76)\n",
      "(32, 46)\n",
      "(32, 59)\n",
      "(32, 82)\n",
      "(32, 81)\n",
      "(32, 65)\n",
      "(32, 84)\n",
      "(32, 48)\n",
      "(32, 45)\n",
      "(32, 51)\n",
      "(32, 83)\n",
      "(32, 44)\n",
      "(32, 104)\n",
      "(32, 117)\n",
      "epoch:  2\n",
      "Loss:  0.06987548692197333\n",
      "(32, 120)\n",
      "(32, 71)\n",
      "(32, 119)\n",
      "(32, 55)\n",
      "(32, 96)\n",
      "(32, 128)\n",
      "(32, 80)\n",
      "(32, 50)\n",
      "(32, 46)\n",
      "(32, 57)\n",
      "(32, 112)\n",
      "(32, 97)\n",
      "(32, 103)\n",
      "(32, 56)\n",
      "(32, 48)\n",
      "(32, 81)\n",
      "(32, 56)\n",
      "(32, 124)\n",
      "(32, 84)\n",
      "(32, 41)\n",
      "epoch:  3\n",
      "Loss:  0.06720877302492538\n",
      "(32, 98)\n",
      "(32, 43)\n",
      "(32, 85)\n",
      "(32, 47)\n",
      "(32, 46)\n",
      "(32, 123)\n",
      "(32, 44)\n",
      "(32, 65)\n",
      "(32, 104)\n",
      "(32, 112)\n",
      "(32, 97)\n",
      "(32, 104)\n",
      "(32, 96)\n",
      "(32, 41)\n",
      "(32, 44)\n",
      "(32, 117)\n",
      "(32, 119)\n",
      "(32, 75)\n",
      "(32, 108)\n",
      "(32, 43)\n",
      "(32, 104)\n",
      "(32, 58)\n",
      "epoch:  4\n",
      "Loss:  0.06444015372090225\n",
      "(32, 60)\n",
      "(32, 119)\n",
      "(32, 70)\n",
      "(32, 45)\n",
      "(32, 77)\n",
      "(32, 119)\n",
      "(32, 51)\n",
      "(32, 88)\n",
      "(32, 73)\n",
      "(32, 49)\n",
      "(32, 119)\n",
      "(32, 42)\n",
      "(32, 84)\n",
      "(32, 110)\n",
      "(32, 97)\n",
      "(32, 112)\n",
      "(32, 120)\n",
      "(32, 80)\n",
      "(32, 84)\n",
      "(32, 44)\n",
      "(32, 63)\n",
      "(32, 88)\n",
      "(32, 86)\n",
      "(32, 55)\n",
      "(32, 95)\n",
      "(32, 51)\n",
      "(32, 68)\n",
      "(32, 41)\n",
      "(32, 83)\n",
      "(32, 91)\n",
      "epoch:  5\n",
      "Loss:  0.06270852530511414\n",
      "(32, 56)\n",
      "(32, 53)\n",
      "(32, 93)\n",
      "(32, 52)\n",
      "(32, 53)\n",
      "(32, 78)\n",
      "(32, 119)\n",
      "(32, 55)\n",
      "(32, 101)\n",
      "(32, 107)\n",
      "(32, 90)\n",
      "(32, 122)\n",
      "(32, 56)\n",
      "(32, 84)\n",
      "(32, 122)\n",
      "(32, 69)\n",
      "(32, 69)\n",
      "(32, 90)\n",
      "(32, 47)\n",
      "(32, 75)\n",
      "(32, 51)\n",
      "(32, 104)\n",
      "(32, 92)\n",
      "(32, 106)\n",
      "(32, 74)\n",
      "epoch:  6\n",
      "Loss:  0.0587978403924442\n",
      "(32, 94)\n",
      "(32, 45)\n",
      "(32, 54)\n",
      "(32, 44)\n",
      "(32, 56)\n",
      "(32, 90)\n",
      "(32, 65)\n",
      "(32, 80)\n",
      "(32, 43)\n",
      "(32, 78)\n",
      "(32, 86)\n",
      "(32, 55)\n",
      "(32, 124)\n",
      "(32, 69)\n",
      "(32, 59)\n",
      "(32, 72)\n",
      "(32, 75)\n",
      "(32, 65)\n",
      "(32, 71)\n",
      "(32, 92)\n",
      "(32, 75)\n",
      "(32, 44)\n",
      "(32, 53)\n",
      "(32, 43)\n",
      "(32, 100)\n",
      "(32, 45)\n",
      "(32, 72)\n",
      "(32, 43)\n",
      "(32, 70)\n",
      "(32, 106)\n",
      "(32, 44)\n",
      "epoch:  7\n",
      "Loss:  0.056498168626936476\n",
      "(32, 69)\n",
      "(32, 101)\n",
      "(32, 65)\n",
      "(32, 110)\n",
      "(32, 69)\n",
      "(32, 47)\n",
      "(32, 121)\n",
      "(32, 50)\n",
      "(32, 52)\n",
      "(32, 111)\n",
      "(32, 83)\n",
      "(32, 85)\n",
      "(32, 105)\n",
      "(32, 72)\n",
      "(32, 129)\n",
      "(32, 85)\n",
      "(32, 96)\n",
      "(32, 64)\n",
      "(32, 55)\n",
      "(32, 103)\n",
      "(32, 66)\n",
      "(32, 51)\n",
      "(32, 103)\n",
      "(32, 47)\n",
      "epoch:  8\n",
      "Loss:  0.05157924270847948\n",
      "(32, 56)\n",
      "(32, 116)\n",
      "(32, 62)\n",
      "(32, 42)\n",
      "(32, 77)\n",
      "(32, 114)\n",
      "(32, 58)\n",
      "(32, 121)\n",
      "(32, 44)\n",
      "(32, 41)\n",
      "(32, 93)\n",
      "(32, 60)\n",
      "(32, 59)\n",
      "(32, 52)\n",
      "(32, 120)\n",
      "(32, 124)\n",
      "(32, 103)\n",
      "(32, 49)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f4127c7c83be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                                                                                 \u001b[0mseq_length_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnon_pad_len_whole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                                                                                 \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_state_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_state_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                                                                                 lr: learningrate})\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             [_, l] = sess.run([minimize_evo, loss_evo], feed_dict={b._batch_size_placeholder: batch_size,\n",
      "\u001b[0;32m~/anaconda3/envs/UniRep/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UniRep/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UniRep/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UniRep/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UniRep/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UniRep/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################## Training regeme TBT ###################################\n",
    "\n",
    "# Trunkated backprop parameters\n",
    "grad_stop = 40 # parameter needs to be larger then the difference within a mini-batch\n",
    "size_train = (len(X_train))//batch_size # number of minibatches per training epoch\n",
    "size_val = len(X_val)//batch_size  # number of minibatches per validation epoch\n",
    "epoch = 10\n",
    "learningrate = 0.005\n",
    "\n",
    "# Initiate callback logg arrays\n",
    "loss_acc = np.zeros(epoch)\n",
    "\n",
    "\n",
    "#Initiate session for Evo tuning\n",
    "sess = tf.Session()\n",
    "unirep.initialize_uninitialized(sess)\n",
    "\n",
    "for k in range(epoch):\n",
    "    # Training loop\n",
    "    for i in range(size_train):\n",
    "        index_batch = np.random.randint(0,size_train-batch_size) # creating random variable for batch creation\n",
    "        batch = X_train[index_batch:batch_size+index_batch]\n",
    "        int_seq = list(map(aa_seq_to_int, batch))\n",
    "        non_pad_len_whole = np.array([len(int_seq[i]) for i in range(batch_size)], dtype=np.int32)      \n",
    "        max_len_batch = np.max(non_pad_len_whole)\n",
    "        min_len_batch = np.min(non_pad_len_whole)\n",
    "        index_len = np.random.randint(20,min_len_batch)\n",
    "        non_pad_len_part = np.array([index_len-grad_stop for i in range(batch_size)], dtype=np.int32)\n",
    "        labels = np.zeros((batch_size,20))\n",
    "        tmp = np.zeros((batch_size,index_len-1))\n",
    "        for j, val in enumerate(int_seq):\n",
    "            if val[index_len] <= 20:\n",
    "                labels[j,val[index_len]-1] = 1\n",
    "            tmp[j,:] = np.array(val)[:index_len-1]\n",
    "        int_seq = tmp\n",
    "        \n",
    "\n",
    "        # Truncated gradient decent through time\n",
    "        if index_len-1 > grad_stop:\n",
    "            final_state_, fh_ = sess.run([b._final_state, final_hidden], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                                b._minibatch_x_placeholder: int_seq[:,:-grad_stop],\n",
    "                                                                                seq_length_placeholder: non_pad_len_part,\n",
    "                                                                                b._initial_state_placeholder: b._zero_state})\n",
    "\n",
    "            \n",
    "            [_, l] = sess.run([minimize_evo, loss_evo], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                                b._minibatch_x_placeholder: int_seq[:,-grad_stop:],\n",
    "                                                                                labels_evo: labels,\n",
    "                                                                                seq_length_placeholder: non_pad_len_whole,\n",
    "                                                                                b._initial_state_placeholder: (final_state_[0], fh_),\n",
    "                                                                                lr: learningrate})\n",
    "        else:\n",
    "            [_, l] = sess.run([minimize_evo, loss_evo], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                                b._minibatch_x_placeholder: int_seq,\n",
    "                                                                                labels_evo: labels,\n",
    "                                                                                seq_length_placeholder: non_pad_len_whole,\n",
    "                                                                                b._initial_state_placeholder: b._zero_state,\n",
    "                                                                                lr: learningrate})\n",
    "        loss_acc[k] += l/size_train\n",
    "\n",
    "    \n",
    "    print('epoch: ', k)\n",
    "    print('Loss: ', loss_acc[k])\n",
    "    \n",
    "    #  Simple learning rate decrease algorithm (Should be upgraded to uppdate on plateau) \n",
    "    if k%10 == 0 and k>0:\n",
    "        learningrate *= 0.8\n",
    "        print('learning rate: ', learningrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving new waights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_matrix:0\n",
      "[[ 9.4531631e-01 -6.6362572e-01 -2.4727893e-01 -7.9199553e-01\n",
      "   2.6630306e-01 -6.4838982e-01  4.9781895e-01  3.4055996e-01\n",
      "   2.1549630e-01 -8.5698748e-01]\n",
      " [ 2.4772792e-01  2.9151422e-01 -1.5495698e+00  1.9741470e+00\n",
      "  -1.4079258e+00  2.2512465e+00 -1.0545133e+00  1.9351069e+00\n",
      "   4.7975802e-01  2.1520741e+00]\n",
      " [-2.3115120e+00 -1.1795886e+00 -1.9046620e+00  2.2483774e-02\n",
      "  -3.3014011e+00  1.1442558e+00 -9.5683850e-02  5.4421264e-01\n",
      "   1.6127024e+00  1.1679040e+00]\n",
      " [-3.8656466e+00 -3.2561639e-01 -1.9194684e+00  1.8437387e+00\n",
      "  -1.4309715e+00  1.7897017e+00  3.3095551e-01  1.9604835e-01\n",
      "  -2.2726191e-02  8.1630892e-01]\n",
      " [-2.1821768e+00 -8.5190344e-01 -1.9693266e+00 -7.6698601e-01\n",
      "  -2.5119345e+00  8.3105826e-01 -8.2373492e-02  2.6420088e+00\n",
      "   1.0705485e+00  1.4846184e+00]\n",
      " [-2.9085495e+00 -1.9665563e+00 -1.3311914e+00  2.5400786e+00\n",
      "   7.7433699e-01  1.2669100e+00 -1.0392420e+00  2.1624033e+00\n",
      "   1.6375303e+00 -1.1801726e-01]\n",
      " [-1.3858920e+00 -1.9543687e+00 -1.3055754e+00  1.8730602e+00\n",
      "  -1.6080546e+00  9.2030364e-01 -1.5170186e+00  2.7547398e+00\n",
      "   1.5631441e+00 -3.1472328e-01]\n",
      " [-9.6893901e-01 -1.6923953e+00 -2.1876988e+00  2.0788877e+00\n",
      "  -8.8133675e-01  5.6620461e-01  8.3545876e-01  1.6372091e+00\n",
      "  -1.7590746e-01  2.5064249e+00]\n",
      " [-6.3292539e-01 -1.6236365e+00 -2.8016174e+00  2.1665137e+00\n",
      "  -4.9207649e-01  1.0475546e+00 -2.7523553e-01  8.1114095e-01\n",
      "  -1.2613101e-01  2.5198958e+00]\n",
      " [-2.8609891e+00  3.5450542e-01 -2.6308048e+00  1.6913061e+00\n",
      "   2.3151708e-01  7.5040996e-01  3.1995985e-01  1.7605993e+00\n",
      "   1.3887169e+00  1.9939140e+00]\n",
      " [-6.6602850e-01 -5.6105548e-01 -2.5871928e+00  1.8285911e+00\n",
      "  -2.1446772e+00  9.4440991e-01 -3.4940988e-01  1.8140991e+00\n",
      "   1.6627772e+00  7.9621828e-01]\n",
      " [-4.0780473e+00 -2.0116694e+00  3.2368135e-01  1.8475150e+00\n",
      "  -1.4602029e+00  1.5282367e+00 -1.3458462e+00 -2.5146451e+00\n",
      "   1.4391215e-01  3.1300733e+00]\n",
      " [ 6.1520898e-01  8.8576064e-02  7.6665527e-01 -6.0764408e-01\n",
      "  -8.7106222e-01 -3.3548108e-01 -1.0077764e+00 -1.4958322e-01\n",
      "  -7.6220274e-01  3.3041850e-01]\n",
      " [-1.8511912e+00 -7.1905595e-01  1.4348862e+00  2.5869858e+00\n",
      "  -1.3667845e+00  1.0105991e+00  1.8741615e+00  2.2439148e+00\n",
      "   1.8257465e+00  2.3837168e+00]\n",
      " [ 6.2043928e-02 -3.2736847e+00 -1.3893706e+00 -4.8114184e-01\n",
      "   4.3222493e-01  2.0616820e+00  2.9754870e-02  6.2117481e-01\n",
      "   3.7626262e+00  3.2793882e+00]\n",
      " [-7.2569025e-01 -2.2158847e+00 -2.5241992e-01  2.0819163e+00\n",
      "  -2.2444503e+00  4.3094507e-01 -8.4780902e-01  1.3694192e+00\n",
      "  -1.5810287e-01  2.4226515e+00]\n",
      " [-1.2520834e+00 -9.8388726e-01 -1.8028349e-01  6.7591166e-01\n",
      "  -9.3170255e-01  2.2315776e+00 -2.0350006e+00  1.8134625e+00\n",
      "  -2.6033112e-01  2.6409762e+00]\n",
      " [-1.0692950e+00  1.1149720e-01 -5.3389108e-01  5.3790158e-01\n",
      "  -7.0882595e-01  2.7659721e+00 -1.8574383e+00  1.9849159e+00\n",
      "   6.0804907e-02  2.7648523e+00]\n",
      " [-6.4943516e-01 -5.6689155e-01 -1.0384930e+00  1.5192324e+00\n",
      "  -1.3515882e+00  4.2624030e+00  4.0192643e-01  1.0301532e+00\n",
      "  -6.9721413e-01  1.4341180e+00]\n",
      " [-1.9911091e+00 -1.3076411e+00 -1.1460954e+00  8.4384602e-01\n",
      "  -1.1556282e+00  4.2438135e+00  7.9870236e-01  1.3123866e+00\n",
      "  -1.2827841e+00  5.9779400e-01]\n",
      " [-5.4970664e-01 -2.2591465e+00 -2.2416873e-01  2.0769715e+00\n",
      "  -2.7200284e+00  5.0330982e+00  4.2660257e-01 -4.8142746e-01\n",
      "   7.8381479e-01 -4.9773729e-01]\n",
      " [-4.1644064e-01  6.7698336e-01 -1.0159934e+00  1.8974878e+00\n",
      "  -1.5638245e+00  2.6532547e+00 -1.5955237e+00  6.9002271e-01\n",
      "   1.0747768e+00  2.3882880e+00]\n",
      " [ 4.8707011e-01 -4.6883270e-01  8.4259784e-01 -3.7028305e-03\n",
      "   8.3193463e-01  3.6631551e-01  4.4701961e-01  4.6858677e-01\n",
      "  -6.7318869e-01  4.6946589e-02]\n",
      " [-2.4841523e-01 -7.8847647e-02 -9.7334170e-01  2.6094627e-01\n",
      "   2.7083182e-01 -6.1169386e-02 -3.5592604e-01 -9.2001724e-01\n",
      "   4.5677471e-01 -3.1811309e-01]\n",
      " [ 2.7419362e+00  1.8390716e+00 -2.2923462e+00 -8.0174810e-01\n",
      "  -1.8923078e+00  4.1142631e+00  2.3014941e+00 -1.2462398e+00\n",
      "   3.5051177e+00 -1.1950938e+00]\n",
      " [-4.0053439e-01 -4.2918682e-01 -6.9176984e-01  6.9427896e-01\n",
      "   7.9518843e-01 -4.0332770e-01 -5.2031207e-01  6.7869163e-01\n",
      "  -2.5721478e-01  5.9246588e-01]]\n",
      "rnn/mlstm/mlstm/wx:0\n",
      "[[ 0.13334069  0.20462722 -0.472816   ...  0.47707272  0.33937132\n",
      "  -0.05510983]\n",
      " [-0.03094146  0.22861835  0.00454293 ...  0.38417497  0.11118149\n",
      "  -0.07066426]\n",
      " [ 0.49443045  0.27343932 -0.16480117 ...  0.46109888  0.10842676\n",
      "   0.09728463]\n",
      " ...\n",
      " [ 0.2610419  -0.50838125  0.17212024 ... -0.3973041  -0.49406558\n",
      "  -0.14602736]\n",
      " [ 0.33332276 -0.6299906   0.15776576 ... -0.32316887  0.10626587\n",
      "   0.07529916]\n",
      " [-0.21313    -0.44430107 -0.0182569  ... -0.07549854 -0.14199491\n",
      "  -0.27969962]]\n",
      "rnn/mlstm/mlstm/wh:0\n",
      "[[-0.04377436 -0.12977293 -0.01407778 ...  0.07464714 -0.06227884\n",
      "  -0.05469138]\n",
      " [-0.01507972 -0.06142078 -0.01912836 ... -0.05474389 -0.04902587\n",
      "   0.03934774]\n",
      " [-0.05239395 -0.0580533  -0.00031191 ...  0.08594946  0.06263944\n",
      "   0.10104991]\n",
      " ...\n",
      " [ 0.09219045  0.17785004 -0.02575628 ... -0.10852657  0.0008411\n",
      "   0.02688094]\n",
      " [-0.02004765 -0.05059555 -0.01588184 ... -0.01335579 -0.00392315\n",
      "  -0.01370375]\n",
      " [-0.00923826  0.05484278  0.02788945 ... -0.11747503  0.02007518\n",
      "   0.06967524]]\n",
      "rnn/mlstm/mlstm/wmx:0\n",
      "[[ 0.3900852   0.72261655  0.10302471 ...  0.99528426  0.11143238\n",
      "  -0.08683509]\n",
      " [ 0.2556459   0.10808432 -1.0984322  ...  0.0736966   0.07501457\n",
      "  -0.0199243 ]\n",
      " [-0.02124116 -0.36143976  0.08202206 ... -0.07086686  0.19573398\n",
      "   0.20408182]\n",
      " ...\n",
      " [ 0.15850568  0.6480044  -0.06606567 ...  0.06843347 -0.16866675\n",
      "   0.4455288 ]\n",
      " [ 0.3331269  -0.07185048 -0.24845564 ... -0.06896336  0.01605464\n",
      "  -0.0696148 ]\n",
      " [-0.47483984 -0.23785861  0.07289809 ...  0.00289457 -0.29833642\n",
      "   0.45017588]]\n",
      "rnn/mlstm/mlstm/wmh:0\n",
      "[[ 0.11723815 -0.20450655 -0.01561907 ... -0.0687026  -0.02422906\n",
      "  -0.05834781]\n",
      " [ 0.06220415 -0.01500547 -0.10588939 ... -0.07529152  0.11421211\n",
      "  -0.09033031]\n",
      " [ 0.03246533  0.00232522 -0.0364076  ... -0.00235111 -0.09447394\n",
      "  -0.05105371]\n",
      " ...\n",
      " [ 0.0238953   0.00391681 -0.00751896 ...  0.12090284 -0.01981371\n",
      "  -0.07532155]\n",
      " [-0.09206825 -0.05402055 -0.00313375 ...  0.08327339 -0.1145827\n",
      "   0.07216292]\n",
      " [ 0.05069423  0.09381855 -0.00371988 ... -0.19141755  0.02715003\n",
      "   0.18690915]]\n",
      "rnn/mlstm/mlstm/b:0\n",
      "[2.897026  2.7702985 2.9864933 ... 3.0359561 3.0091407 2.999047 ]\n",
      "rnn/mlstm/mlstm/gx:0\n",
      "[0.59358895 0.83375984 0.9805967  ... 0.8355157  0.79747653 0.897334  ]\n",
      "rnn/mlstm/mlstm/gh:0\n",
      "[1.5089453  1.2061111  1.0837184  ... 1.001405   1.0432212  0.98165125]\n",
      "rnn/mlstm/mlstm/gmx:0\n",
      "[1.521617  1.8198513 1.8968337 ... 1.1812303 1.2309004 1.3669624]\n",
      "rnn/mlstm/mlstm/gmh:0\n",
      "[1.521263  1.818832  1.8959442 ... 1.1807514 1.2306442 1.3664693]\n",
      "fully_connected/weights:0\n",
      "[[-0.03350692  0.11348381 -0.19417556 ... -0.10971051 -0.15858378\n",
      "  -0.4906729 ]\n",
      " [ 0.02240712  0.01771946 -0.00779512 ...  0.01255773  0.00212687\n",
      "   0.05521936]\n",
      " [-0.07720477 -0.13511926 -0.15476796 ...  0.02096441  0.08575926\n",
      "   0.03795281]\n",
      " ...\n",
      " [ 0.0020066  -0.00463982 -0.01683434 ...  0.00745005  0.00971781\n",
      "  -0.0711223 ]\n",
      " [ 0.00771013 -0.01809541 -0.03234737 ...  0.01433956  0.03234308\n",
      "  -0.03394968]\n",
      " [-0.09768613 -0.02059432 -0.05693785 ...  0.08336044  0.07140396\n",
      "  -0.01360478]]\n",
      "fully_connected/biases:0\n",
      "[ -1.6553072   -0.1933485   -1.2341405   -0.05390557  -0.6068514\n",
      "  -0.32983142  -0.2511692   -0.8680709   -0.8119297   -0.96696043\n",
      "  -1.3169992   -9.940155    -0.5684856   -0.43278247  -0.89821136\n",
      "  -0.9932946   -1.1634444   -1.3374249   -1.4653924   -1.9513999\n",
      "  -0.6341813  -10.071764   -10.071646   -10.06729      1.3458178 ]\n"
     ]
    }
   ],
   "source": [
    "save_only_lstm = True\n",
    "dir_name = \"new_1900_weights\"\n",
    "\n",
    "\n",
    "vs = tf.trainable_variables()\n",
    "top_var = [i.name for i in tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"top\")]\n",
    "for v in vs:\n",
    "    name = v.name\n",
    "    if save_only_lstm:\n",
    "        if name not in top_var:\n",
    "            value = sess.run(v)\n",
    "            print(name)\n",
    "            print(value)\n",
    "            np.save(os.path.join(dir_name,name.replace('/', '_') + \".npy\"), np.array(value))\n",
    "    else:\n",
    "        value = sess.run(v)\n",
    "        print(name)\n",
    "        print(value)\n",
    "        np.save(os.path.join(dir_name,name.replace('/', '_') + \".npy\"), np.array(value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate feature reprecentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq:  0\n",
      "seq:  32\n",
      "seq:  64\n",
      "seq:  96\n",
      "seq:  128\n",
      "seq:  160\n",
      "seq:  192\n",
      "seq:  224\n",
      "seq:  256\n",
      "seq:  288\n",
      "seq:  320\n",
      "seq:  352\n",
      "seq:  384\n",
      "seq:  416\n",
      "seq:  448\n",
      "seq:  480\n",
      "seq:  512\n",
      "seq:  544\n",
      "seq:  576\n",
      "seq:  608\n",
      "seq:  640\n",
      "seq:  672\n",
      "seq:  704\n",
      "seq:  736\n",
      "seq:  768\n",
      "seq:  800\n",
      "seq:  832\n",
      "seq:  864\n",
      "seq:  896\n",
      "seq:  928\n",
      "seq:  960\n",
      "seq:  992\n",
      "seq:  1024\n",
      "seq:  1056\n",
      "seq:  1088\n",
      "seq:  1120\n",
      "seq:  1152\n",
      "seq:  1184\n",
      "seq:  1216\n",
      "seq:  1248\n",
      "seq:  1280\n",
      "seq:  1312\n",
      "seq:  1344\n",
      "seq:  1376\n",
      "seq:  1408\n",
      "seq:  1440\n",
      "seq:  1472\n",
      "seq:  1504\n",
      "seq:  1536\n",
      "seq:  1568\n",
      "seq:  1600\n",
      "seq:  1632\n",
      "seq:  1664\n",
      "seq:  1696\n",
      "seq:  1728\n",
      "seq:  1760\n",
      "seq:  1792\n",
      "seq:  1824\n",
      "seq:  1856\n",
      "seq:  1888\n"
     ]
    }
   ],
   "source": [
    "# You may run in to allocation problem with large data sets \n",
    "\n",
    "# File system setup and initialisation\n",
    "path = 'features/f_'+str(hid)\n",
    "name1 = 'TOPT_avg_' + str(hid) + '.npy'\n",
    "name2 = 'TOPT_final_' + str(hid) + '.npy'\n",
    "name3 = 'TOPT_cell_' + str(hid) + '.npy'\n",
    "arr1 = np.zeros([len(unirep_dict['seq']),hid],dtype=np.float32)\n",
    "arr2 = np.zeros([len(unirep_dict['seq']),hid],dtype=np.float32)\n",
    "arr3 = np.zeros([len(unirep_dict['seq']),hid],dtype=np.float32)\n",
    "\n",
    "# sort unirep_dict to spead up algorithm\n",
    "sorted_zip = sorted(zip(unirep_dict['id'], unirep_dict['property_ogt'], unirep_dict['seq']), key=lambda pair: len(pair[2]))\n",
    "unirep_dict['id'] = [id_ for id_, _, _ in sorted_zip]\n",
    "unirep_dict['property_ogt'] = [prop for _ ,prop,_ in sorted_zip]\n",
    "unirep_dict['seq'] = [seq for _ ,_, seq in sorted_zip]\n",
    "\n",
    "# Feature generation algorithm\n",
    "for k in range(0,len(unirep_dict['seq']),batch_size):\n",
    "    batch = unirep_dict['seq'][k:k+batch_size]\n",
    "    b_size = len(batch)\n",
    "    int_seq = list(map(aa_seq_to_int, batch))\n",
    "    non_pad_len_ = np.array([len(int_seq[i])-1 for i in range(len(int_seq))], dtype=np.int32)\n",
    "    max_len_batch = np.max(non_pad_len_)\n",
    "    min_len_batch = np.min(non_pad_len_)\n",
    "    tmp = np.zeros([batch_size, max_len_batch+1], dtype=np.float32)\n",
    "    for j, seq in enumerate(int_seq):\n",
    "        tmp[j,:len(seq)] = seq\n",
    "    int_seq = tmp\n",
    "\n",
    "    final_state_, hs = sess.run([b._final_state, b._output], feed_dict={b._batch_size_placeholder: batch_size,\n",
    "                                                                        b._minibatch_x_placeholder: int_seq,\n",
    "                                                                        b._initial_state_placeholder: (np.zeros( [batch_size, 1900], dtype=np.float32),\n",
    "                                                                                                       np.zeros([batch_size,1900], dtype=np.float32))})\n",
    "\n",
    "\n",
    "    rep1 = sess.run([features], feed_dict={hidden_states_p: hs,\n",
    "                                            non_pad_len_p: non_pad_len_,\n",
    "                                            size: non_pad_len_.size})\n",
    "\n",
    "    arr1[k:k+b_size,:] = rep1[0]\n",
    "    arr2[k:k+b_size,:] = final_state_[0][0]\n",
    "    arr3[k:k+b_size,:] = final_state_[1][0]\n",
    "    print('seq: ', k)\n",
    "\n",
    "# Saving arrays and orderd id & property\n",
    "np.save(os.path.join(path,name1),arr1)\n",
    "np.save(os.path.join(path,name2),arr2)\n",
    "np.save(os.path.join(path,name3),arr3)\n",
    "f = open(os.path.join(path,'TOPT_id.txt'),'w')\n",
    "for i in unirep_dict['id']:\n",
    "    f.write(i+'\\n')\n",
    "f.close()\n",
    "f = open(os.path.join(path,'TOPT_property.txt'),'w')\n",
    "for i in unirep_dict['property_ogt']:\n",
    "    f.write(str(i)+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
